{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3b3451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Number of events: 1\tchi = 22.250000000000000000\t||g|| = 9.433981132056603158\tpred = nan\tared = nan\tnorm_update = nan\ttr_radius = nan\n",
      "Iteration 1: Number of events: 1\tchi = 13.816018867943393289\t||g|| = 7.433981132056603158\tpred = 9.433981132056606711\tared = 8.433981132056606711\tnorm_update = 1.000000000000000222\ttr_radius = 1.000000000000000222\n",
      "Iteration 2: Number of events: 1\tchi = 0.000000000000000000\t||g|| = 0.000000000000003972\tpred = 27.632037735886772367\tared = 13.816018867943393289\tnorm_update = 3.716990566028299803\ttr_radius = 3.716990566028299803\n",
      "\n",
      "Optimization finished.\n",
      "Optimized x: [1.  2.5]\n",
      "Final misfit: 3.944304526105059e-30\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "\n",
    "calls = []  # store (x, f, g) for analysis\n",
    "prev = {\"x\": None, \"f\": None, \"g\": None}  # for comparing consecutive iterations\n",
    "iteration = 0  # iteration counter\n",
    "\n",
    "\n",
    "def forward(m):\n",
    "    u = (m[0] - 1.0, m[1] - 2.5)\n",
    "    return u\n",
    "\n",
    "\n",
    "def fun_with_grad(m):\n",
    "    global iteration, prev\n",
    "\n",
    "    # Forward and gradient\n",
    "    u = forward(m)\n",
    "    chi = u[0]**2 + u[1]**2\n",
    "    g = np.array([2*(m[0]-1.0), 2*(m[1]-2.5)])\n",
    "\n",
    "    # Store\n",
    "    calls.append((m.copy(), float(chi), g.copy()))\n",
    "\n",
    "    # Compute diagnostics if previous exists\n",
    "    if prev[\"x\"] is None:\n",
    "        pred = ared = norm_update = tr_radius = np.nan\n",
    "    else:\n",
    "        s = m - prev[\"x\"]\n",
    "        ared = prev[\"f\"] - chi\n",
    "        pred = -np.dot(prev[\"g\"], s)\n",
    "        norm_update = np.linalg.norm(s)\n",
    "        tr_radius = norm_update\n",
    "\n",
    "    # Print formatted info\n",
    "    print(\n",
    "        f\"Iteration {iteration}: Number of events: 1\\t\"\n",
    "        f\"chi = {chi:.18f}\\t||g|| = {np.linalg.norm(g):.18f}\\t\"\n",
    "        f\"pred = {pred:.18f}\\tared = {ared:.18f}\\t\"\n",
    "        f\"norm_update = {norm_update:.18f}\\ttr_radius = {tr_radius:.18f}\"\n",
    "    )\n",
    "\n",
    "    # Update previous for next iteration\n",
    "    prev = {\"x\": m.copy(), \"f\": chi, \"g\": g.copy()}\n",
    "    iteration += 1\n",
    "\n",
    "    return chi, g\n",
    "\n",
    "\n",
    "# Initial model\n",
    "m0 = np.array([5.0, 5.0])\n",
    "\n",
    "# Run optimizer\n",
    "x_opt, f_opt, info = fmin_l_bfgs_b(fun_with_grad, m0, maxiter=1)\n",
    "\n",
    "print(\"\\nOptimization finished.\")\n",
    "print(\"Optimized x:\", x_opt)\n",
    "print(\"Final misfit:\", f_opt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salvus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
